%This section contains work progress
In this section is described work progress in each iteration.

\subsection{Initialization}
\comment[anyone]{Adam}{Add proper rank of Honza}\\
TextAn team visited policeman Jan Hořínek, who introduced us his work and showed
us existing inadequate software whose extension we should prepare. Basis of the
project should be processing police reports - recognize entities and match them
to existing objects in the database. We should use Webservices to provide easy
way to integrate the project to the current system. He promised us models and
example data inputs and expected outputs. We divided the work as follows:

\begin{itemize}
\item \textbf{Petr Fanta} - entities recognition and input parsing, look for useful existing solutions
\item \textbf{Adam Huječek} - GUI validation, component schema and communication
\item \textbf{Václav Pernička} - database
\item \textbf{Peter Šípoš} - web service, graph GUI, testing
\item \textbf{Jakub Vlček} - entities recognition and input parsing, look for useful existing solutions
\end{itemize}

We made some decisions and requirements for each component:

\paragraph{Database}
\comment{Jakub}{attach document schema here?}
At the beginning, we made database schema, which was approved after a few
iterations. We paid attention mainly on schema generality because we want to
support more than one (police) domain.\\
Database should support versioning, parallel processing, partial records. We
decided to create special layer between server and database because of
generality (it will be easier to change database system). Logging (users,
changes) support should not be missing. Problem could be with merging two
objects into new one, so we should create special functionality and table in the
database.

\paragraph{Client}
We decided for pipeline model. This means that report processing will consist of more successive phases:

\begin{enumerate}
\item Report insertion
\item Report editing
\item (Auto) Entity recognition
\item Entity editing (entity types, ranges, creating new ones)
\item (Auto) Object recognition
\item Object editing (adding new ones, repair bad connections between entities and objects)
\item (Auto) Relationships recognition
\item Relationships editing
\item Report confirmed and sent to server
\end{enumerate}

Changes in each phase are not stored in the database immediately but they are
stored locally and write to database follows confirmation. Problem is with
machine recognition, because models with newly added items are trained after final confirmation, so we can't use just machine learning output. We decided, that newly added items will be preferred over recognized ones
 
\subsection{Design \& technologies}
In November, we mainly chose and tested technologies which we could use. Peter
Sipos left \textan{}, but Duc Tam Hoang joined us. His specialization is
linguistic and machine learning so he will be really useful for our project.
Because he is Vietnamese student we had to changed project language to English.
His main task will be NER and entity-object matching. We were trying different
entity recognizers, but there are not many applicable for Czech. Milan Straka
promised us his project NameTag. It is named entity recognizer for Czech, so
exactly what we need. Problem is, that it is not finished yet and in C++
language, so there must be additional layer between Java and C++.
We researched possibilities about entity-object matching. Program will get
entity and assign it possible candidates from objects. This part could not be
purely automatic because of ambiguity, but if there will be high probability,
program should match object entity pair automatically.

Possible solutions for this entity-object matching are machine learning  methods
ranking or classification.

\comment{Petr}{This is not true! In the end we use WEKA, because JavaML project is probably dead.
Also new versions of WEKA are probably more powerful and fits our needs (provide probability from classification) }
We looked for suitable Java library which provides machine learning techniques.
Candidates were JavaML and Weka. After testing these two libraries, we chose
JavaML, because it provides more machine learnig algorithms (some of them uses
Weka library). Weka's problem is that it was created for teaching purposes so
it's performance is not as good as JavaML.

There were two possible server architectures: standalone or embedded webserver
(Tomcat or Jetty). We considered usage of some technologies like Spring, CXF and
Hibernate for database layer.

\subsection{Prototyping \& interconnecting}
After choosing technologies, we made some prototypes of each component. We
discussed a lot APIs (we need them for testing). For testing purposes, we must
provide some mock objects, so everyone implemented mock of his component.
NameTag was released, so we started acquainting with it. After meeting with Milan Straka, where he presented us NameTag, we started becoming more familiar with it and stared testing it.
There were problems with compiling and Java bindings, which took more time than we expected. Problem was missing documentation.
We connected client and database to server, implemented database data browsing on client (mainly graphs viewing with JUNG).
Tam made prototype of object matcher, but it was not integrated to server.

\subsection{Main coding}
When we made a prototype of whole program, everyone started improving his component in his own branch.
\paragraph{Server} Server was debugged and made reliable. It starts using WSDLs so there were lot of work on server and client parts. Result was, that Java code is now generated automatically. Connection to database was reworked to use Spring Beans.
\paragraph{Named entity recognizer} NameTag was fully integrated to server. We started editing it for our purposes (using our structures and types). There were problems with gazetteers files and translating entities from NameTag to Textan.
After receiving information that NameTag will not support JNI to training parts, we researching how to launch training binaries from Java.
\paragraph{Client} Client was reworked to pipeline as we need, we improved graph viewing to support oriented edges.
\paragraph{Object matcher} TextPro (as we called entity-object matching) has first prototype. It uses ranking and than, if ranking has poor result, classification.
\paragraph{Database} Database has new layer with DAOs, so no more need to access database directly.
After this iteration, we released first alpha version of TextAn.

\subsection{Improving}
Alpha version of NameTag learning was implemented. There were few problems with portability because of different architectures and operating systems. After implementation of special functions in database, we made automatic data extraction for learning. For this purpose, new function to server was added - commands. It is implementation of design pattern Command, which started data generation and model training after new report insertion. Models managing implemented due to bigger size (deleting old ones) 
Database support logging. It was done through interceptors - triggers in Hibernate layer.
In client, there were lots of small fixes in GUI, problems were with portability between Windows and Unix-like systems, where ControlsFX and JavaFX behave differently.
TextPro received many new features. We integrated Morphodita because we needed it's tagger for new features.
Settings through properties files are now supported in each component.

\subsection{Bugfixing \& documentation}
